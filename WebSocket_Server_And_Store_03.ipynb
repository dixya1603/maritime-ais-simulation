{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93aebb8f-51c9-4535-893f-0376bccaac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 📌 STEP 0: SETUP AND CLEANUP: Remove Old Database if Exists\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfad720-ad63-4ff4-99cc-2d267e18738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Deleted old database: ais_data.sqlite\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "db_path = \"ais_data.sqlite\"\n",
    "\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "    print(f\"🧹 Deleted old database: {db_path}\")\n",
    "else:\n",
    "    print(\"✅ No existing database found. You're good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9b9712-6be6-45f2-af1f-2d03b0620a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 📌 STEP 1: IMPORT REQUIRED LIBRARIES\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d6fc2b-6b95-43b7-9c0f-b33718b032db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pyais import decode\n",
    "from geopy.distance import geodesic\n",
    "from collections import defaultdict\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f57c76-4e75-4b25-b245-9de06ced8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 📌 STEP 2: LOAD AIS DATA\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a059ee3a-4f04-4502-aa3c-ffa24c108940",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ais_data.json\", \"r\") as f:\n",
    "    ais_data = json.load(f)\n",
    "\n",
    "DB_NAME = \"ais_data.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c348c6-5097-460a-be47-b69690c8c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 📌 STEP 3: DATABASE INITIALIZATION & VALIDATION\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27706c11-908a-4622-9dc8-25deafb4d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_db():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS ais_messages (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            mmsi INTEGER,\n",
    "            timestamp TEXT,\n",
    "            lat REAL,\n",
    "            lon REAL,\n",
    "            speed REAL,\n",
    "            heading INTEGER,\n",
    "            course REAL,\n",
    "            raw_payload TEXT,\n",
    "            UNIQUE(mmsi, timestamp)\n",
    "        )\n",
    "    ''')\n",
    "    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_timestamp ON ais_messages (timestamp)\")\n",
    "    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_mmsi ON ais_messages (mmsi)\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def save_to_db(parsed, mmsi, timestamp, raw_payload):\n",
    "    # Validate coordinates and timestamp\n",
    "    if not (-90 <= parsed.lat <= 90): return False\n",
    "    if not (-180 <= parsed.lon <= 180): return False\n",
    "    timestamp_without_Z = timestamp.rstrip('Z')\n",
    "    if pd.to_datetime(timestamp_without_Z, errors='coerce', utc=True) is pd.NaT:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect(DB_NAME)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            INSERT OR IGNORE INTO ais_messages\n",
    "            (mmsi, timestamp, lat, lon, speed, heading, course, raw_payload)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            mmsi, timestamp, parsed.lat, parsed.lon,\n",
    "            parsed.speed, parsed.heading, parsed.course, raw_payload\n",
    "        ))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        return True\n",
    "    except sqlite3.IntegrityError:\n",
    "        return \"duplicate\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error saving to DB: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6065374-a5ed-43ab-adec-f49e7b9ab321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 📌 STEP 4: STREAM AND STORE FUNCTION\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17b2086e-8516-4973-8499-938e9b36595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 100/11487 messages...\n",
      "✅ Processed 200/11487 messages...\n",
      "✅ Processed 300/11487 messages...\n",
      "✅ Processed 400/11487 messages...\n",
      "✅ Processed 500/11487 messages...\n",
      "✅ Processed 600/11487 messages...\n",
      "✅ Processed 700/11487 messages...\n",
      "✅ Processed 800/11487 messages...\n",
      "✅ Processed 900/11487 messages...\n",
      "✅ Processed 1000/11487 messages...\n",
      "✅ Processed 1100/11487 messages...\n",
      "✅ Processed 1200/11487 messages...\n",
      "✅ Processed 1300/11487 messages...\n",
      "✅ Processed 1400/11487 messages...\n",
      "✅ Processed 1500/11487 messages...\n",
      "✅ Processed 1600/11487 messages...\n",
      "✅ Processed 1700/11487 messages...\n",
      "✅ Processed 1800/11487 messages...\n",
      "✅ Processed 1900/11487 messages...\n",
      "✅ Processed 2000/11487 messages...\n",
      "✅ Processed 2100/11487 messages...\n",
      "✅ Processed 2200/11487 messages...\n",
      "✅ Processed 2300/11487 messages...\n",
      "✅ Processed 2400/11487 messages...\n",
      "✅ Processed 2500/11487 messages...\n",
      "✅ Processed 2600/11487 messages...\n",
      "✅ Processed 2700/11487 messages...\n",
      "✅ Processed 2800/11487 messages...\n",
      "✅ Processed 2900/11487 messages...\n",
      "✅ Processed 3000/11487 messages...\n",
      "✅ Processed 3100/11487 messages...\n",
      "✅ Processed 3200/11487 messages...\n",
      "✅ Processed 3300/11487 messages...\n",
      "✅ Processed 3400/11487 messages...\n",
      "✅ Processed 3500/11487 messages...\n",
      "✅ Processed 3600/11487 messages...\n",
      "✅ Processed 3700/11487 messages...\n",
      "✅ Processed 3800/11487 messages...\n",
      "✅ Processed 3900/11487 messages...\n",
      "✅ Processed 4000/11487 messages...\n",
      "✅ Processed 4100/11487 messages...\n",
      "✅ Processed 4200/11487 messages...\n",
      "✅ Processed 4300/11487 messages...\n",
      "✅ Processed 4400/11487 messages...\n",
      "✅ Processed 4500/11487 messages...\n",
      "✅ Processed 4600/11487 messages...\n",
      "✅ Processed 4700/11487 messages...\n",
      "✅ Processed 4800/11487 messages...\n",
      "✅ Processed 4900/11487 messages...\n",
      "✅ Processed 5000/11487 messages...\n",
      "✅ Processed 5100/11487 messages...\n",
      "✅ Processed 5200/11487 messages...\n",
      "✅ Processed 5300/11487 messages...\n",
      "✅ Processed 5400/11487 messages...\n",
      "✅ Processed 5500/11487 messages...\n",
      "✅ Processed 5600/11487 messages...\n",
      "✅ Processed 5700/11487 messages...\n",
      "✅ Processed 5800/11487 messages...\n",
      "✅ Processed 5900/11487 messages...\n",
      "✅ Processed 6000/11487 messages...\n",
      "✅ Processed 6100/11487 messages...\n",
      "✅ Processed 6200/11487 messages...\n",
      "✅ Processed 6300/11487 messages...\n",
      "✅ Processed 6400/11487 messages...\n",
      "✅ Processed 6500/11487 messages...\n",
      "✅ Processed 6600/11487 messages...\n",
      "✅ Processed 6700/11487 messages...\n",
      "✅ Processed 6800/11487 messages...\n",
      "✅ Processed 6900/11487 messages...\n",
      "✅ Processed 7000/11487 messages...\n",
      "✅ Processed 7100/11487 messages...\n",
      "✅ Processed 7200/11487 messages...\n",
      "✅ Processed 7300/11487 messages...\n",
      "✅ Processed 7400/11487 messages...\n",
      "✅ Processed 7500/11487 messages...\n",
      "✅ Processed 7600/11487 messages...\n",
      "✅ Processed 7700/11487 messages...\n",
      "✅ Processed 7800/11487 messages...\n",
      "✅ Processed 7900/11487 messages...\n",
      "✅ Processed 8000/11487 messages...\n",
      "✅ Processed 8100/11487 messages...\n",
      "✅ Processed 8200/11487 messages...\n",
      "✅ Processed 8300/11487 messages...\n",
      "✅ Processed 8400/11487 messages...\n",
      "✅ Processed 8500/11487 messages...\n",
      "✅ Processed 8600/11487 messages...\n",
      "✅ Processed 8700/11487 messages...\n",
      "✅ Processed 8800/11487 messages...\n",
      "✅ Processed 8900/11487 messages...\n",
      "✅ Processed 9000/11487 messages...\n",
      "✅ Processed 9100/11487 messages...\n",
      "✅ Processed 9200/11487 messages...\n",
      "✅ Processed 9300/11487 messages...\n",
      "✅ Processed 9400/11487 messages...\n",
      "✅ Processed 9500/11487 messages...\n",
      "✅ Processed 9600/11487 messages...\n",
      "✅ Processed 9700/11487 messages...\n",
      "✅ Processed 9800/11487 messages...\n",
      "✅ Processed 9900/11487 messages...\n",
      "✅ Processed 10000/11487 messages...\n",
      "✅ Processed 10100/11487 messages...\n",
      "✅ Processed 10200/11487 messages...\n",
      "✅ Processed 10300/11487 messages...\n",
      "✅ Processed 10400/11487 messages...\n",
      "✅ Processed 10500/11487 messages...\n",
      "✅ Processed 10600/11487 messages...\n",
      "✅ Processed 10700/11487 messages...\n",
      "✅ Processed 10800/11487 messages...\n",
      "✅ Processed 10900/11487 messages...\n",
      "✅ Processed 11000/11487 messages...\n",
      "✅ Processed 11100/11487 messages...\n",
      "✅ Processed 11200/11487 messages...\n",
      "✅ Processed 11300/11487 messages...\n",
      "✅ Processed 11400/11487 messages...\n",
      "\n",
      "🎉 Done! 11487 saved, 0 duplicates, 0 invalid.\n",
      "\n",
      "📊 First 5 rows from DB:\n",
      "(1, 123456789, '2025-04-30T09:38:40.869824+00:00Z', 30.732393, 121.827393, 18.0, 90, 90.0, '!AIVDO,1,1,,A,11mg=5OP2l8ecW`AUM33Q2l1P000,0*69')\n",
      "(2, 123456789, '2025-04-30T09:43:40.869824+00:00Z', 30.735913, 121.85671, 18.0, 90, 90.0, '!AIVDO,1,1,,A,11mg=5OP2l8el=DAUUC3Q2l1P000,0*40')\n",
      "(3, 123456789, '2025-04-30T09:48:40.869824+00:00Z', 30.739435, 121.886028, 18.0, 90, 90.0, '!AIVDO,1,1,,A,11mg=5OP2l8etk2AUeSCQ2l1P000,0*28')\n",
      "(4, 123456789, '2025-04-30T09:53:40.869824+00:00Z', 30.742955, 121.915345, 18.0, 90, 90.0, '!AIVDO,1,1,,A,11mg=5OP2l8f5HfAUmkCQ2l1P000,0*2D')\n",
      "(5, 123456789, '2025-04-30T09:58:40.869824+00:00Z', 30.746477, 121.944663, 18.0, 90, 90.0, '!AIVDO,1,1,,A,11mg=5OP2l8f=vLAUv3SQ2l1P000,0*62')\n"
     ]
    }
   ],
   "source": [
    "async def stream_and_store_combined():\n",
    "    initialize_db()\n",
    "    count = 0\n",
    "    invalid_count = 0\n",
    "    duplicate_count = 0\n",
    "    total = len(ais_data)\n",
    "\n",
    "    for i, msg in enumerate(ais_data):\n",
    "        try:\n",
    "            decoded = decode(msg[\"payload\"])\n",
    "            result = save_to_db(decoded, msg[\"mmsi\"], msg[\"timestamp\"], msg[\"payload\"])\n",
    "            if result == True:\n",
    "                count += 1\n",
    "            elif result == \"duplicate\":\n",
    "                duplicate_count += 1\n",
    "            else:\n",
    "                invalid_count += 1\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"✅ Processed {i+1}/{total} messages...\")\n",
    "        except Exception as e:\n",
    "            invalid_count += 1\n",
    "            print(f\"⚠️ Malformed at {msg['timestamp']}: {e}\")\n",
    "\n",
    "    print(f\"\\n🎉 Done! {count} saved, {duplicate_count} duplicates, {invalid_count} invalid.\")\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    rows = conn.execute(\"SELECT * FROM ais_messages LIMIT 5\").fetchall()\n",
    "    print(\"\\n📊 First 5 rows from DB:\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    conn.close()\n",
    "\n",
    "# Run the async function\n",
    "await stream_and_store_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db548cc1-bae7-425c-a3f4-f73c9f3efb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# 📌 STEP 5: DATABASE INSPECTION & SAMPLE OUTPUT\n",
    "# -----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb864f7d-2a0d-420a-bef6-5db8482568f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Tables: [('ais_messages',), ('sqlite_sequence',)]\n",
      "📦 Total AIS Messages: 11487\n",
      "🛥️ Distinct Vessels: 3\n",
      "⏰ Time Range: 2025-04-30T09:38:40.869824+00:00Z → 2025-05-18T11:38:41.054395+00:00Z\n",
      "✅ Coordinate validation passed.\n",
      "\n",
      "📋 Sample 5 rows for each MMSI:\n",
      "\n",
      "🚢 MMSI 123456789:\n",
      "   id       mmsi                          timestamp        lat         lon  \\\n",
      "0   1  123456789  2025-04-30T09:38:40.869824+00:00Z  30.732393  121.827393   \n",
      "1   2  123456789  2025-04-30T09:43:40.869824+00:00Z  30.735913  121.856710   \n",
      "2   3  123456789  2025-04-30T09:48:40.869824+00:00Z  30.739435  121.886028   \n",
      "3   4  123456789  2025-04-30T09:53:40.869824+00:00Z  30.742955  121.915345   \n",
      "4   5  123456789  2025-04-30T09:58:40.869824+00:00Z  30.746477  121.944663   \n",
      "\n",
      "   speed  heading  course                                      raw_payload  \n",
      "0   18.0       90    90.0  !AIVDO,1,1,,A,11mg=5OP2l8ecW`AUM33Q2l1P000,0*69  \n",
      "1   18.0       90    90.0  !AIVDO,1,1,,A,11mg=5OP2l8el=DAUUC3Q2l1P000,0*40  \n",
      "2   18.0       90    90.0  !AIVDO,1,1,,A,11mg=5OP2l8etk2AUeSCQ2l1P000,0*28  \n",
      "3   18.0       90    90.0  !AIVDO,1,1,,A,11mg=5OP2l8f5HfAUmkCQ2l1P000,0*2D  \n",
      "4   18.0       90    90.0  !AIVDO,1,1,,A,11mg=5OP2l8f=vLAUv3SQ2l1P000,0*62  \n",
      "\n",
      "🚢 MMSI 192837465:\n",
      "     id       mmsi                          timestamp       lat       lon  \\\n",
      "0  9031  192837465  2025-04-30T09:38:41.202311+00:00Z  40.70810 -73.97790   \n",
      "1  9032  192837465  2025-04-30T09:43:41.202311+00:00Z  40.73715 -73.96385   \n",
      "2  9033  192837465  2025-04-30T09:48:41.202311+00:00Z  40.76620 -73.94980   \n",
      "3  9034  192837465  2025-04-30T09:53:41.202311+00:00Z  40.78180 -73.92710   \n",
      "4  9035  192837465  2025-04-30T09:58:41.202311+00:00Z  40.79740 -73.90440   \n",
      "\n",
      "   speed  heading  course                                      raw_payload  \n",
      "0   16.0       90    90.0  !AIVDO,1,1,,A,12oqoFOP2PJeFjHGBiW3Q2l1P000,0*70  \n",
      "1   16.0       90    90.0  !AIVDO,1,1,,A,12oqoFOP2PJeJqlGCmdSQ2l1P000,0*15  \n",
      "2   16.0       90    90.0  !AIVDO,1,1,,A,12oqoFOP2PJeO1@GDqj3Q2l1P000,0*09  \n",
      "3   16.0       90    90.0  !AIVDO,1,1,,A,12oqoFOP2PJeUbpGENF3Q2l1P000,0*62  \n",
      "4   16.0       90    90.0  !AIVDO,1,1,,A,12oqoFOP2PJedDPGF2r3Q2l1P000,0*1E  \n",
      "\n",
      "🚢 MMSI 987654321:\n",
      "     id       mmsi                          timestamp    lat         lon  \\\n",
      "0  3822  987654321  2025-04-30T09:38:41.054395+00:00Z  1.100  103.600000   \n",
      "1  3823  987654321  2025-04-30T09:43:41.054395+00:00Z  1.115  103.573333   \n",
      "2  3824  987654321  2025-04-30T09:48:41.054395+00:00Z  1.130  103.546667   \n",
      "3  3825  987654321  2025-04-30T09:53:41.054395+00:00Z  1.145  103.520000   \n",
      "4  3826  987654321  2025-04-30T09:58:41.054395+00:00Z  1.160  103.493333   \n",
      "\n",
      "   speed  heading  course                                      raw_payload  \n",
      "0   22.0       90    90.0  !AIVDO,1,1,,A,1>eq`dOP3L7J?T00`B83Q2l1P000,0*3A  \n",
      "1   22.0       90    90.0  !AIVDO,1,1,,A,1>eq`dOP3L7J7h00`mB3Q2l1P000,0*5B  \n",
      "2   22.0       90    90.0  !AIVDO,1,1,,A,1>eq`dOP3L7Iwt00aHL3Q2l1P000,0*2E  \n",
      "3   22.0       90    90.0  !AIVDO,1,1,,A,1>eq`dOP3L7Ip800asV3Q2l1P000,0*44  \n",
      "4   22.0       90    90.0  !AIVDO,1,1,,A,1>eq`dOP3L7IhD00bNh3Q2l1P000,0*20  \n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(DB_NAME)\n",
    "\n",
    "tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "print(f\"\\n📋 Tables: {tables}\")\n",
    "\n",
    "total_rows = conn.execute(\"SELECT COUNT(*) FROM ais_messages\").fetchone()[0]\n",
    "print(f\"📦 Total AIS Messages: {total_rows}\")\n",
    "\n",
    "distinct_mmsi = conn.execute(\"SELECT COUNT(DISTINCT mmsi) FROM ais_messages\").fetchone()[0]\n",
    "print(f\"🛥️ Distinct Vessels: {distinct_mmsi}\")\n",
    "\n",
    "time_range = conn.execute(\"SELECT MIN(timestamp), MAX(timestamp) FROM ais_messages\").fetchone()\n",
    "print(f\"⏰ Time Range: {time_range[0]} → {time_range[1]}\")\n",
    "\n",
    "invalid_coords = conn.execute(\"\"\"\n",
    "SELECT COUNT(*) FROM ais_messages\n",
    "WHERE lat NOT BETWEEN -90 AND 90\n",
    "   OR lon NOT BETWEEN -180 AND 180\n",
    "\"\"\").fetchone()[0]\n",
    "print(\"✅ Coordinate validation passed.\" if invalid_coords == 0 else f\"⚠️ Invalid coordinates: {invalid_coords}\")\n",
    "\n",
    "mmsi_list = [row[0] for row in conn.execute(\"SELECT DISTINCT mmsi FROM ais_messages\").fetchall()]\n",
    "print(\"\\n📋 Sample 5 rows for each MMSI:\")\n",
    "for mmsi in mmsi_list:\n",
    "    print(f\"\\n🚢 MMSI {mmsi}:\")\n",
    "    sample = pd.read_sql_query(f\"\"\"\n",
    "        SELECT * FROM ais_messages\n",
    "        WHERE mmsi = {mmsi}\n",
    "        ORDER BY timestamp\n",
    "        LIMIT 5\n",
    "    \"\"\", conn)\n",
    "    print(sample)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f058601-698e-4327-9cab-3d3f8f6546b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 📌 STEP 6: UNIT TESTING FOR DB\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06406ecc-35e9-4a4e-a9c0-8b1c688c961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.030s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1cf6cbb17f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestAISDatabase(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.conn = sqlite3.connect(DB_NAME)\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.conn.close()\n",
    "\n",
    "    def test_data_exists(self):\n",
    "        count = self.conn.execute(\"SELECT COUNT(*) FROM ais_messages\").fetchone()[0]\n",
    "        self.assertGreater(count, 0, \"Database should have data.\")\n",
    "\n",
    "    def test_lat_lon_valid(self):\n",
    "        df = pd.read_sql_query(\"SELECT lat, lon FROM ais_messages LIMIT 100\", self.conn)\n",
    "        self.assertTrue(df['lat'].between(-90, 90).all(), \"Latitudes must be valid\")\n",
    "        self.assertTrue(df['lon'].between(-180, 180).all(), \"Longitudes must be valid\")\n",
    "\n",
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dc4b21-a16c-4fc7-b291-a5f6c651ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# 📌 STEP 7: ANALYTICS: DISTANCE AND SPEED CALCULATION\n",
    "# -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c52698-31e5-48db-a828-314b385c6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Vessel Distance and Speed Summary:\n",
      "\n",
      "🚢 Shanghai → Los Angeles (MMSI 123456789):\n",
      "📏 Distance: 10700.66 km\n",
      "🚀 Avg Speed: 33.61 km/h\n",
      "\n",
      "🚢 Singapore → Sydney (MMSI 987654321):\n",
      "📏 Distance: 17842.91 km\n",
      "🚀 Avg Speed: 41.11 km/h\n",
      "\n",
      "🚢 New York → Rotterdam (MMSI 192837465):\n",
      "📏 Distance: 6176.98 km\n",
      "🚀 Avg Speed: 30.18 km/h\n"
     ]
    }
   ],
   "source": [
    "vessels_info = {\n",
    "    123456789: \"Shanghai → Los Angeles\",\n",
    "    987654321: \"Singapore → Sydney\",\n",
    "    192837465: \"New York → Rotterdam\"\n",
    "}\n",
    "\n",
    "def get_full_track(mmsi, start_time=None, end_time=None):\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    query = f\"\"\"\n",
    "    SELECT timestamp, lat, lon, speed, heading, course\n",
    "    FROM ais_messages\n",
    "    WHERE mmsi = {mmsi}\n",
    "    \"\"\"\n",
    "    if start_time and end_time:\n",
    "        query += f\" AND timestamp BETWEEN '{start_time}' AND '{end_time}'\"\n",
    "    query += \" ORDER BY timestamp\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "def calculate_distance_and_speed(df):\n",
    "    if df.empty or len(df) < 2:\n",
    "        return None, None\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"].str.replace(\"Z\", \"\", regex=False), utc=True, errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"timestamp\"])\n",
    "    df[\"latitude\"] = df[\"lat\"]\n",
    "    df[\"longitude\"] = df[\"lon\"]\n",
    "\n",
    "    total_distance_km = sum(\n",
    "        geodesic((df.iloc[i-1][\"latitude\"], df.iloc[i-1][\"longitude\"]),\n",
    "                 (df.iloc[i][\"latitude\"], df.iloc[i][\"longitude\"])).km\n",
    "        for i in range(1, len(df))\n",
    "    )\n",
    "    time_diff_hours = (df[\"timestamp\"].iloc[-1] - df[\"timestamp\"].iloc[0]).total_seconds() / 3600\n",
    "    avg_speed = total_distance_km / time_diff_hours if time_diff_hours > 0 else 0\n",
    "\n",
    "    return total_distance_km, avg_speed\n",
    "\n",
    "print(\"\\n📋 Vessel Distance and Speed Summary:\")\n",
    "for mmsi, vessel_name in vessels_info.items():\n",
    "    df_track = get_full_track(mmsi)\n",
    "    distance, avg_speed = calculate_distance_and_speed(df_track)\n",
    "    if distance is not None:\n",
    "        print(f\"\\n🚢 {vessel_name} (MMSI {mmsi}):\")\n",
    "        print(f\"📏 Distance: {distance:.2f} km\")\n",
    "        print(f\"🚀 Avg Speed: {avg_speed:.2f} km/h\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️ {vessel_name} (MMSI {mmsi}): Not enough data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591bb2a-638d-45ae-9df0-0958d4e45fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
